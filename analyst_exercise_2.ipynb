{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6 color='#4a86e8'><b><i>Analyst Exercise 2</i></b></font><p align=\"right\">Calculate scroll rates for the top 10 articles</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i><font size=4 color='#4a86e8'>Import packages</font></i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i><font size=4 color='#4a86e8'>First let's define a helper function that will clean the data<br>(this function standardizes column names, inserts a numeric Percentile column and checks for duplicated PagePaths)</font></i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(df, target):\n",
    "    # If the target already exists, cancel since data prep already done\n",
    "    if 'Target' in df.head():\n",
    "        print('Data prep already completed')\n",
    "        return df\n",
    "    \n",
    "    # If the target is Pageviews, the data source is GA, and the pageviews need to be 'unsampled'\n",
    "    if target == 'Pageviews':\n",
    "        print('WARNING: \"unsampling\" target column')\n",
    "        df['Pageviews'] = df.EventAction.apply(lambda x: 10 if x != 'Scroll 90%' else 1) * df['Pageviews']\n",
    "    \n",
    "    # Add a numeric Percentile column\n",
    "    if 'Percentile' not in df.head():\n",
    "        df.insert(2, 'Percentile', [int(re.sub('[^0-9]', '', s))/100 for s in df['EventAction']])\n",
    "    \n",
    "    # Rename the target column to 'Target' to standardize\n",
    "    df = df.rename(columns={target: 'Target'})\n",
    "    new_names = ', '.join(df.head())\n",
    "    print(f'New column names: {new_names}')\n",
    "    \n",
    "    # Lowercase all of the PagePaths then check for duplicates\n",
    "    df = df.assign(PagePath = [d.lower() for d in df['PagePath']])\n",
    "    dups = df[df.duplicated(subset=['PagePath', 'EventAction'], keep=False)].sort_values(by=['PagePath', 'EventAction'])\n",
    "    \n",
    "    # If there are duplicates offer the option to clean them up\n",
    "    if len(dups) > 0:\n",
    "        if input('Duplicates detected, would you like to view them (y/n)?') == 'y':\n",
    "            print(dups)\n",
    "        \n",
    "        if input('Would you like to consolidate duplicates (y/n)?') == 'y':\n",
    "            deduped = dups.groupby(['PagePath', 'EventAction', 'Percentile']).sum().reset_index()\n",
    "            \n",
    "            orig_len = len(df)\n",
    "            \n",
    "            df = df.drop_duplicates(subset=['PagePath', 'EventAction'], keep=False).append(deduped).reset_index(drop=True)\n",
    "            \n",
    "            print(f'{orig_len - len(df)} rows removed')\n",
    "            \n",
    "            if input('Would you like to see the result of de-duplication (y/n)?') == 'y':\n",
    "                print(df)\n",
    "                \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i><font size=4 color='#4a86e8'>Load csv data and preview</font></i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.read_csv('~/AnalystExercises/Data/scroll_depth.csv') # Define the source data here\n",
    "dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i><font size=4 color='#4a86e8'>Prep the data using the helper function above.<br>(the function will standardize column names, add a numeric Percentile column check for clean duplicates)</font></i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = prep_data(dat, 'Pageviews')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i><font size=4 color='#4a86e8'>Define a function to calculate the average scroll rate for each subset of the dataframe\n",
    "<br>Sum of (# of views per each percentile * the percentile)/total pageviews</font></i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_scroll_rate(x):\n",
    "    return round(sum([(row['Target'] * row['Percentile']) for index, row in x.iterrows()])/sum(x['Target']), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i><b><font size=4 color='#4a86e8'>Finally, we can group our page paths, apply the scroll rate calculation, and view the results</i></b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = dat.groupby('PagePath')\n",
    "\n",
    "avg_scrolls = grouped.apply(avg_scroll_rate).sort_values(ascending=False).rename('AvgScrollRateGA').to_frame()\n",
    "\n",
    "dat_agg = dat.filter(['PagePath', 'Target']).groupby('PagePath').sum().rename(columns={'Target': 'TargetGA'})\n",
    "\n",
    "results = dat_agg.merge(avg_scrolls, on='PagePath', how='left').sort_values(by='AvgScrollRateGA', ascending=False)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font size=4 color='#4a86e8'>Let's compare the results above with those from BigQuery</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_bq = pd.read_csv('~/AnalystExercises/Data/scroll_depth_bq.csv') # Define the source data here\n",
    "\n",
    "dat_bq = prep_data(dat_bq, 'UnsampledEventCount')\n",
    "\n",
    "grouped_bq = dat_bq.groupby('PagePath')\n",
    "\n",
    "avg_scrolls_bq = grouped_bq.apply(avg_scroll_rate).sort_values(ascending=False).rename('AvgScrollRateBQ').to_frame()\n",
    "\n",
    "dat_agg_bq = dat_bq.filter(['PagePath', 'Target']).groupby('PagePath').sum().rename(columns={'Target': 'TargetBQ'})\n",
    "\n",
    "results_bq = dat_agg_bq.merge(avg_scrolls_bq, on='PagePath', how='left').sort_values(by='AvgScrollRateBQ', ascending=False)\n",
    "\n",
    "results_comp = results.merge(results_bq, on='PagePath', how='left')\n",
    "\n",
    "for c in ['Target', 'AvgScrollRate']:\n",
    "    results_comp[f'{c} Err (%)'] = round(100 * (results_comp[f'{c}BQ'] - results_comp[f'{c}GA']) / results_comp[f'{c}GA'], 2)\n",
    "\n",
    "results_comp = results_comp.reindex(columns=['TargetGA', 'TargetBQ', 'Target Err (%)', 'AvgScrollRateGA', 'AvgScrollRateBQ', 'AvgScrollRate Err (%)'])\n",
    "    \n",
    "results_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
